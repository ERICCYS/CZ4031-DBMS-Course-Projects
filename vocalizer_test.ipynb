{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import json\n",
    "import argparse\n",
    "import copy\n",
    "import random, string\n",
    "import os\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, node_type, relation_name, schema, alias, group_key, sort_key, join_type, index_name, \n",
    "            hash_cond, table_filter, index_cond, merge_cond, recheck_cond, join_filter, subplan_name, actual_rows,\n",
    "            actual_time):\n",
    "        self.node_type = node_type\n",
    "        self.children = []\n",
    "        self.relation_name = relation_name\n",
    "        self.schema = schema\n",
    "        self.alias = alias\n",
    "        self.group_key = group_key\n",
    "        self.sort_key = sort_key\n",
    "        self.join_type = join_type\n",
    "        self.index_name = index_name\n",
    "        self.hash_cond = hash_cond\n",
    "        self.table_filter = table_filter\n",
    "        self.index_cond = index_cond\n",
    "        self.merge_cond = merge_cond\n",
    "        self.recheck_cond = recheck_cond\n",
    "        self.join_filter = join_filter\n",
    "        self.subplan_name = subplan_name\n",
    "        self.actual_rows = actual_rows\n",
    "        self.actual_time = actual_time\n",
    "\n",
    "    def add_children(self, child):\n",
    "        self.children.append(child)\n",
    "    \n",
    "    def set_output_name(self, output_name):\n",
    "        if \"T\" == output_name[0] and output_name[1:].isdigit():\n",
    "            self.output_name = int(output_name[1:])\n",
    "        else:\n",
    "            self.output_name = output_name\n",
    "\n",
    "    def get_output_name(self):\n",
    "        if str(self.output_name).isdigit():\n",
    "            return \"T\" + str(self.output_name)\n",
    "        else:\n",
    "            return self.output_name\n",
    "\n",
    "    def set_step(self, step):\n",
    "        self.step = step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1\n",
    "def parse_json(json_file):\n",
    "    q = queue.Queue()\n",
    "    q_node = queue.Queue()\n",
    "    json_obj = json.load(open(json_file, 'r'))\n",
    "    plan = json_obj[0]['Plan']\n",
    "    q.put(plan)\n",
    "    q_node.put(None)\n",
    "\n",
    "    while not q.empty():\n",
    "        current_plan = q.get()\n",
    "        parent_node = q_node.get()\n",
    "\n",
    "        relation_name = schema = alias = group_key = sort_key = join_type = index_name = hash_cond = table_filter \\\n",
    "            = index_cond = merge_cond = recheck_cond = join_filter = subplan_name = actual_rows = actual_time = None\n",
    "        if 'Relation Name' in current_plan:\n",
    "            relation_name = current_plan['Relation Name']\n",
    "        if 'Schema' in current_plan:\n",
    "            schema = current_plan['Schema']\n",
    "        if 'Alias' in current_plan:\n",
    "            alias = current_plan['Alias']\n",
    "        if 'Group Key' in current_plan:\n",
    "            group_key = current_plan['Group Key']\n",
    "        if 'Sort Key' in current_plan:\n",
    "            sort_key = current_plan['Sort Key']\n",
    "        if 'Join Type' in current_plan:\n",
    "            join_type = current_plan['Join Type']\n",
    "        if 'Index Name' in current_plan:\n",
    "            index_name = current_plan['Index Name']\n",
    "        if 'Hash Cond' in current_plan:\n",
    "            hash_cond = current_plan['Hash Cond']\n",
    "        if 'Filter' in current_plan:\n",
    "            table_filter = current_plan['Filter']\n",
    "        if 'Index Cond' in current_plan:\n",
    "            index_cond = current_plan['Index Cond']\n",
    "        if 'Merge Cond' in current_plan:\n",
    "            merge_cond = current_plan['Merge Cond']\n",
    "        if 'Recheck Cond' in current_plan:\n",
    "            recheck_cond = current_plan['Recheck Cond']\n",
    "        if 'Join Filter' in current_plan:\n",
    "            join_filter = current_plan['Join Filter']\n",
    "        if 'Actual Rows' in current_plan:\n",
    "            actual_rows = current_plan['Actual Rows']\n",
    "        if 'Actual Total Time' in current_plan:\n",
    "            actual_time = current_plan['Actual Total Time']\n",
    "        if 'Subplan Name' in current_plan:\n",
    "            if \"returns\" in current_plan['Subplan Name']:\n",
    "                name = current_plan['Subplan Name']\n",
    "                subplan_name = name[name.index(\"$\"):-1]\n",
    "            else:\n",
    "                subplan_name = current_plan['Subplan Name']\n",
    "\n",
    "        current_node = Node(current_plan['Node Type'], relation_name, schema, alias, group_key, sort_key, join_type,\n",
    "                            index_name, hash_cond, table_filter, index_cond, merge_cond, recheck_cond, join_filter,\n",
    "                            subplan_name, actual_rows, actual_time)\n",
    "\n",
    "        if \"Limit\" == current_node.node_type:\n",
    "            current_node.plan_rows = current_plan['Plan Rows']\n",
    "           \n",
    "        if \"Scan\" in current_node.node_type:\n",
    "            if \"Index\" in current_node.node_type:\n",
    "                if relation_name:\n",
    "                    current_node.set_output_name(relation_name + \" with index \" + index_name)\n",
    "            elif \"Subquery\" in current_node.node_type:\n",
    "                current_node.set_output_name(alias)\n",
    "            else:\n",
    "                current_node.set_output_name(relation_name)\n",
    "\n",
    "        if parent_node is not None:\n",
    "            parent_node.add_children(current_node)\n",
    "        else:\n",
    "            head_node = current_node\n",
    "\n",
    "        if 'Plans' in current_plan:\n",
    "            for item in current_plan['Plans']:\n",
    "                # push child plans into queue\n",
    "                q.put(item)\n",
    "                # push parent for each child into queue\n",
    "                q_node.put(current_node)\n",
    "\n",
    "    return head_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2\n",
    "def simplify_graph(node):\n",
    "    new_node = copy.deepcopy(node)\n",
    "    new_node.children = []\n",
    "\n",
    "    for child in node.children:\n",
    "        new_child = simplify_graph(child)\n",
    "        new_node.add_children(new_child)\n",
    "        new_node.actual_time -= child.actual_time\n",
    "\n",
    "    if node.node_type in [\"Result\"]:\n",
    "        return node.children[0]\n",
    "\n",
    "    return new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3\n",
    "def to_text(node, skip=False):\n",
    "    global steps, cur_step, cur_table_name\n",
    "    increment = True\n",
    "    # skip the child if merge it with current node\n",
    "    if node.node_type in [\"Unique\", \"Aggregate\"] and len(node.children) == 1 \\\n",
    "            and (\"Scan\" in node.children[0].node_type or node.children[0].node_type == \"Sort\"):\n",
    "        children_skip = True\n",
    "    elif node.node_type == \"Bitmap Heap Scan\" and node.children[0].node_type == \"Bitmap Index Scan\":\n",
    "        children_skip = True\n",
    "    else:\n",
    "        children_skip = False\n",
    "\n",
    "    # recursive\n",
    "    for child in node.children:\n",
    "        if node.node_type == \"Aggregate\" and len(node.children) > 1 and child.node_type == \"Sort\":\n",
    "            to_text(child, True)\n",
    "        else:\n",
    "            to_text(child, children_skip)\n",
    "\n",
    "    if node.node_type in [\"Hash\"] or skip:\n",
    "        return\n",
    "\n",
    "    step = \"\"\n",
    "\n",
    "    # generate natural language for various QEP operators\n",
    "    if \"Join\" in node.node_type:\n",
    "        \n",
    "        # special preprocessing for joins\n",
    "        if node.join_type == \"Semi\":\n",
    "            # add the word \"Semi\" before \"Join\" into node.node_type\n",
    "            node_type_list = node.node_type.split()\n",
    "            node_type_list.insert(-1, node.join_type)\n",
    "            node.node_type = \" \".join(node_type_list)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if \"Hash\" in node.node_type:\n",
    "            step += \" and perform \" + node.node_type.lower() + \" on \"\n",
    "            for i, child in enumerate(node.children):\n",
    "                if child.node_type == \"Hash\":\n",
    "                    child.set_output_name(child.children[0].get_output_name())\n",
    "                    hashed_table = child.get_output_name()\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\"table \" + child.get_output_name())\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "            # combine hash with hash join\n",
    "            step = \"hash table \" + hashed_table + step + \" under condition \" + parse_cond(\"Hash Cond\", node.hash_cond, table_subquery_name_pair)\n",
    "        \n",
    "        elif \"Merge\" in node.node_type:\n",
    "            step += \"perform \" + node.node_type.lower() + \" on \"\n",
    "            any_sort = False  # whether sort is performed on any table\n",
    "            for i, child in enumerate(node.children):\n",
    "                if child.node_type == \"Sort\":\n",
    "                    child.set_output_name(child.children[0].get_output_name())\n",
    "                    any_sort = True\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\"table \" + child.get_output_name())\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "            # combine sort with merge join\n",
    "            if any_sort:\n",
    "                sort_step = \"sort \"\n",
    "                for child in node.children:\n",
    "                    if child.node_type == \"Sort\":\n",
    "                        if i < len(node.children) - 1:\n",
    "                            sort_step += (\"table \" + child.get_output_name())\n",
    "                        else:\n",
    "                            sort_step += (\" and table \" + child.get_output_name())\n",
    "                step = sort_step + \" and \" + step\n",
    "\n",
    "    elif node.node_type == \"Bitmap Heap Scan\":\n",
    "        # combine bitmap heap scan and bitmap index scan\n",
    "        if \"Bitmap Index Scan\" in node.children[0].node_type:\n",
    "            node.children[0].set_output_name(node.relation_name)\n",
    "            step = \" with index condition \" + parse_cond(\"Recheck Cond\", node.recheck_cond, table_subquery_name_pair)\n",
    "            \n",
    "        step = \"perform bitmap heap scan on table \" + node.children[0].get_output_name() + step\n",
    "\n",
    "    elif \"Scan\" in node.node_type:\n",
    "        if node.node_type == \"Seq Scan\":\n",
    "            step += \"perform sequential scan on table \"         \n",
    "        else:\n",
    "            step += \"perform \" + node.node_type.lower() + \" on table \" \n",
    "\n",
    "        step += node.get_output_name()\n",
    "\n",
    "        # if no table filter, remain original table name\n",
    "        if not node.table_filter:\n",
    "            increment = False\n",
    "\n",
    "    elif node.node_type == \"Unique\":\n",
    "        # combine unique and sort\n",
    "        if \"Sort\" in node.children[0].node_type:\n",
    "            node.children[0].set_output_name(node.children[0].children[0].get_output_name())\n",
    "            step = \"sort \" + node.children[0].get_output_name() \n",
    "            if node.children[0].sort_key:\n",
    "                step += \" with attribute \" + parse_cond(\"Sort Key\", node.children[0].sort_key, table_subquery_name_pair) +  \" and \"\n",
    "            else:\n",
    "                step += \" and \"\n",
    "\n",
    "        step += \"perform unique on table \" + node.children[0].get_output_name()\n",
    "\n",
    "    elif node.node_type == \"Aggregate\":\n",
    "        for child in node.children:\n",
    "            # combine aggregate and sort\n",
    "            if \"Sort\" in child.node_type:\n",
    "                child.set_output_name(child.children[0].get_output_name())\n",
    "                step = \"sort \" + child.get_output_name() + \" and \"\n",
    "            # combine aggregate with scan\n",
    "            if \"Scan\" in child.node_type:\n",
    "                if child.node_type == \"Seq Scan\":\n",
    "                    step = \"perform sequential scan on \" + child.get_output_name() + \" and \"\n",
    "                else:\n",
    "                    step = \"perform \" + child.node_type.lower() + \" on \" + child.get_output_name() + \" and \"\n",
    "\n",
    "        step += \"perform aggregate on table \" + node.children[0].get_output_name() \n",
    "        if len(node.children) == 2:\n",
    "            step += \" and table \" + node.children[1].get_output_name()\n",
    "\n",
    "    elif node.node_type == \"Sort\":\n",
    "        step += \"perform sort on table \" + node.children[0].get_output_name() + \" with attribute \" + parse_cond(\"Sort Key\", node.sort_key, table_subquery_name_pair) \n",
    "\n",
    "    elif node.node_type == \"Limit\":\n",
    "        step += \"limit the result from table \" + node.children[0].get_output_name() + \" to \" + str(node.plan_rows) + \" record(s)\"\n",
    "    \n",
    "    else:\n",
    "        step += \"perform \" + node.node_type.lower() + \" on\"\n",
    "        # binary operator\n",
    "        if len(node.children) > 1:\n",
    "            for i, child in enumerate(node.children):\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\" table \" + child.get_output_name() + \",\")\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "        # unary operator\n",
    "        else:\n",
    "            step += \" table \" + node.children[0].get_output_name()\n",
    "\n",
    "    # add conditions\n",
    "    if node.group_key:\n",
    "        step += \" with grouping on attribute \" + parse_cond(\"Group Key\", node.group_key, table_subquery_name_pair) \n",
    "    if node.table_filter:\n",
    "        step += \" and filtering on \" + parse_cond(\"Table Filter\", node.table_filter, table_subquery_name_pair)\n",
    "    if node.join_filter:\n",
    "        step += \" while filtering on \" + parse_cond(\"Join Filter\", node.join_filter, table_subquery_name_pair) \n",
    "\n",
    "    # set intermediate table name\n",
    "    if increment:\n",
    "        node.set_output_name(\"T\" + str(cur_table_name))\n",
    "        step += \" to get intermediate table \" + node.get_output_name()\n",
    "        cur_table_name += 1\n",
    "    if node.subplan_name:\n",
    "        table_subquery_name_pair[node.subplan_name] = node.get_output_name()\n",
    "\n",
    "    step = \"Step \" + str(cur_step) + \", \" + step + \".\"\n",
    "    node.set_step(cur_step)\n",
    "    cur_step += 1\n",
    "\n",
    "    steps.append(step) \n",
    "\n",
    "\n",
    "def random_word(length):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for _ in range(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--json_file JSON_FILE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/eric/Library/Jupyter/runtime/kernel-24c6a3aa-49dd-4185-974c-d17368b77797.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/.pyenv/versions/3.7.2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Phase 4\n",
    "def vocalize(steps):\n",
    "    logger = logging.getLogger(\"neuron.vocalizer.vocalize\")\n",
    "    txt = \"\"\n",
    "    for step in steps:\n",
    "        # pronounce the dot sign if it's not period\n",
    "        step = step.replace(\".\", \" dot \")\n",
    "        txt += step[:-5] + \". \"\n",
    "\n",
    "    random_name = random_word(10) + '.mp3'\n",
    "    random_file = os.path.join(os.path.dirname(os.path.realpath(__file__)), random_name)\n",
    "    \n",
    "    tts = gTTS(text=txt, lang='en')\n",
    "    logger.debug(\"Obtained TTS result from Google\")\n",
    "    with open(random_file, 'wb') as f:\n",
    "        tts.save(f.name)\n",
    "\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(f.name)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "\n",
    "def get_text(json_file):\n",
    "    global steps, cur_step, cur_table_name, table_subquery_name_pair\n",
    "    global current_plan_tree\n",
    "    steps = [\"The query is executed as follow.\"]\n",
    "    cur_step = 1\n",
    "    cur_table_name = 1\n",
    "    table_subquery_name_pair = {}\n",
    "\n",
    "    head_node = parse_json(json_file)\n",
    "    handler.current_plan_tree = simplified_graph = simplify_graph(head_node)\n",
    "\n",
    "    to_text(simplified_graph)\n",
    "    if \" to get intermediate table\" in steps[-1]:\n",
    "        steps[-1] = steps[-1][:steps[-1].index(\" to get intermediate table\")] + ' to get the final result.'\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--json_file',  type=str, default='./', help='the json generated file for vocalization')\n",
    "    args = parser.parse_args()\n",
    "    steps = get_text(args.json_file)\n",
    "    vocalize(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_1/query_1a.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Plan': {'Node Type': 'Sort', 'Parallel Aware': False, 'Startup Cost': 5783.27, 'Total Cost': 5783.57, 'Plan Rows': 120, 'Plan Width': 226, 'Sort Key': ['(avg(customer.acctbal)) DESC'], 'Plans': [{'Node Type': 'Aggregate', 'Strategy': 'Sorted', 'Partial Mode': 'Finalize', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Startup Cost': 5748.43, 'Total Cost': 5779.13, 'Plan Rows': 120, 'Plan Width': 226, 'Group Key': ['nation.name'], 'Plans': [{'Node Type': 'Gather Merge', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Startup Cost': 5748.43, 'Total Cost': 5776.43, 'Plan Rows': 240, 'Plan Width': 250, 'Workers Planned': 2, 'Plans': [{'Node Type': 'Sort', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Startup Cost': 4748.4, 'Total Cost': 4748.7, 'Plan Rows': 120, 'Plan Width': 250, 'Sort Key': ['nation.name'], 'Plans': [{'Node Type': 'Aggregate', 'Strategy': 'Hashed', 'Partial Mode': 'Partial', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Startup Cost': 4743.06, 'Total Cost': 4744.26, 'Plan Rows': 120, 'Plan Width': 250, 'Group Key': ['nation.name'], 'Plans': [{'Node Type': 'Hash Join', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Join Type': 'Inner', 'Startup Cost': 12.7, 'Total Cost': 4430.56, 'Plan Rows': 62500, 'Plan Width': 226, 'Inner Unique': True, 'Hash Cond': '(customer.nationkey = nation.nationkey)', 'Plans': [{'Node Type': 'Seq Scan', 'Parent Relationship': 'Outer', 'Parallel Aware': True, 'Relation Name': 'customer', 'Alias': 'customer', 'Startup Cost': 0.0, 'Total Cost': 4248.0, 'Plan Rows': 62500, 'Plan Width': 12}, {'Node Type': 'Hash', 'Parent Relationship': 'Inner', 'Parallel Aware': False, 'Startup Cost': 11.2, 'Total Cost': 11.2, 'Plan Rows': 120, 'Plan Width': 222, 'Plans': [{'Node Type': 'Seq Scan', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Relation Name': 'nation', 'Alias': 'nation', 'Startup Cost': 0.0, 'Total Cost': 11.2, 'Plan Rows': 120, 'Plan Width': 222}]}]}]}]}]}]}]}}]\n"
     ]
    }
   ],
   "source": [
    "with open(json_file) as jf:\n",
    "    data = json.load(jf)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_node = parse_json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sort'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_node.node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate\n"
     ]
    }
   ],
   "source": [
    "for node in head_node.children:\n",
    "    print(node.node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_node_info(head_node):\n",
    "    print(head_node.node_type)\n",
    "    print(len(head_node.children))\n",
    "    print(head_node.children)\n",
    "    print(head_node.relation_name)\n",
    "    print(head_node.schema)\n",
    "    print(head_node.alias)\n",
    "    print(head_node.group_key)\n",
    "    print(head_node.sort_key)\n",
    "    print(head_node.join_type)\n",
    "    print(head_node.index_name)\n",
    "    print(head_node.hash_cond)\n",
    "    print(head_node.table_filter)\n",
    "    print(head_node.index_cond)\n",
    "    print(head_node.merge_cond)\n",
    "    print(head_node.recheck_cond)\n",
    "    print(head_node.join_filter)\n",
    "    print(head_node.subplan_name)\n",
    "    print(head_node.actual_rows)\n",
    "    print(head_node.actual_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gather Merge\n",
      "1\n",
      "[<__main__.Node object at 0x102b730f0>]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print_node_info(head_node.children[0].children[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -=: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cce3b1247058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimplify_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-eae9f1fc270e>\u001b[0m in \u001b[0;36msimplify_graph\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnew_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplify_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eae9f1fc270e>\u001b[0m in \u001b[0;36msimplify_graph\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnew_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplify_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eae9f1fc270e>\u001b[0m in \u001b[0;36msimplify_graph\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnew_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplify_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eae9f1fc270e>\u001b[0m in \u001b[0;36msimplify_graph\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnew_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplify_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eae9f1fc270e>\u001b[0m in \u001b[0;36msimplify_graph\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnew_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplify_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eae9f1fc270e>\u001b[0m in \u001b[0;36msimplify_graph\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnew_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplify_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnew_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -=: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "simplify_graph(head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
