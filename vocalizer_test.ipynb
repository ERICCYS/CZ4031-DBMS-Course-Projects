{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import json\n",
    "import argparse\n",
    "import copy\n",
    "import random, string\n",
    "import os\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, node_type, relation_name, schema, alias, group_key, sort_key, join_type, index_name, \n",
    "            hash_cond, table_filter, index_cond, merge_cond, recheck_cond, join_filter, subplan_name, actual_rows,\n",
    "            actual_time):\n",
    "        self.node_type = node_type\n",
    "        self.children = []\n",
    "        self.relation_name = relation_name\n",
    "        self.schema = schema\n",
    "        self.alias = alias\n",
    "        self.group_key = group_key\n",
    "        self.sort_key = sort_key\n",
    "        self.join_type = join_type\n",
    "        self.index_name = index_name\n",
    "        self.hash_cond = hash_cond\n",
    "        self.table_filter = table_filter\n",
    "        self.index_cond = index_cond\n",
    "        self.merge_cond = merge_cond\n",
    "        self.recheck_cond = recheck_cond\n",
    "        self.join_filter = join_filter\n",
    "        self.subplan_name = subplan_name\n",
    "        self.actual_rows = actual_rows\n",
    "        self.actual_time = actual_time\n",
    "\n",
    "    def add_children(self, child):\n",
    "        self.children.append(child)\n",
    "    \n",
    "    def set_output_name(self, output_name):\n",
    "        if \"T\" == output_name[0] and output_name[1:].isdigit():\n",
    "            self.output_name = int(output_name[1:])\n",
    "        else:\n",
    "            self.output_name = output_name\n",
    "\n",
    "    def get_output_name(self):\n",
    "        if str(self.output_name).isdigit():\n",
    "            return \"T\" + str(self.output_name)\n",
    "        else:\n",
    "            return self.output_name\n",
    "\n",
    "    def set_step(self, step):\n",
    "        self.step = step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1\n",
    "def parse_json(json_file):\n",
    "    q = queue.Queue()\n",
    "    q_node = queue.Queue()\n",
    "    json_obj = json.load(open(json_file, 'r'))\n",
    "    plan = json_obj[0]['Plan']\n",
    "    q.put(plan)\n",
    "    q_node.put(None)\n",
    "\n",
    "    while not q.empty():\n",
    "        current_plan = q.get()\n",
    "        parent_node = q_node.get()\n",
    "\n",
    "        relation_name = schema = alias = group_key = sort_key = join_type = index_name = hash_cond = table_filter \\\n",
    "            = index_cond = merge_cond = recheck_cond = join_filter = subplan_name = actual_rows = actual_time = None\n",
    "        if 'Relation Name' in current_plan:\n",
    "            relation_name = current_plan['Relation Name']\n",
    "        if 'Schema' in current_plan:\n",
    "            schema = current_plan['Schema']\n",
    "        if 'Alias' in current_plan:\n",
    "            alias = current_plan['Alias']\n",
    "        if 'Group Key' in current_plan:\n",
    "            group_key = current_plan['Group Key']\n",
    "        if 'Sort Key' in current_plan:\n",
    "            sort_key = current_plan['Sort Key']\n",
    "        if 'Join Type' in current_plan:\n",
    "            join_type = current_plan['Join Type']\n",
    "        if 'Index Name' in current_plan:\n",
    "            index_name = current_plan['Index Name']\n",
    "        if 'Hash Cond' in current_plan:\n",
    "            hash_cond = current_plan['Hash Cond']\n",
    "        if 'Filter' in current_plan:\n",
    "            table_filter = current_plan['Filter']\n",
    "        if 'Index Cond' in current_plan:\n",
    "            index_cond = current_plan['Index Cond']\n",
    "        if 'Merge Cond' in current_plan:\n",
    "            merge_cond = current_plan['Merge Cond']\n",
    "        if 'Recheck Cond' in current_plan:\n",
    "            recheck_cond = current_plan['Recheck Cond']\n",
    "        if 'Join Filter' in current_plan:\n",
    "            join_filter = current_plan['Join Filter']\n",
    "        if 'Actual Rows' in current_plan:\n",
    "            actual_rows = current_plan['Actual Rows']\n",
    "        if 'Actual Total Time' in current_plan:\n",
    "            actual_time = current_plan['Actual Total Time']\n",
    "        if 'Subplan Name' in current_plan:\n",
    "            if \"returns\" in current_plan['Subplan Name']:\n",
    "                name = current_plan['Subplan Name']\n",
    "                subplan_name = name[name.index(\"$\"):-1]\n",
    "            else:\n",
    "                subplan_name = current_plan['Subplan Name']\n",
    "\n",
    "        current_node = Node(current_plan['Node Type'], relation_name, schema, alias, group_key, sort_key, join_type,\n",
    "                            index_name, hash_cond, table_filter, index_cond, merge_cond, recheck_cond, join_filter,\n",
    "                            subplan_name, actual_rows, actual_time)\n",
    "\n",
    "        if \"Limit\" == current_node.node_type:\n",
    "            current_node.plan_rows = current_plan['Plan Rows']\n",
    "           \n",
    "        if \"Scan\" in current_node.node_type:\n",
    "            if \"Index\" in current_node.node_type:\n",
    "                if relation_name:\n",
    "                    current_node.set_output_name(relation_name + \" with index \" + index_name)\n",
    "            elif \"Subquery\" in current_node.node_type:\n",
    "                current_node.set_output_name(alias)\n",
    "            else:\n",
    "                current_node.set_output_name(relation_name)\n",
    "\n",
    "        if parent_node is not None:\n",
    "            parent_node.add_children(current_node)\n",
    "        else:\n",
    "            head_node = current_node\n",
    "\n",
    "        if 'Plans' in current_plan:\n",
    "            for item in current_plan['Plans']:\n",
    "                # push child plans into queue\n",
    "                q.put(item)\n",
    "                # push parent for each child into queue\n",
    "                q_node.put(current_node)\n",
    "\n",
    "    return head_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2\n",
    "def simplify_graph(node):\n",
    "    new_node = copy.deepcopy(node)\n",
    "    new_node.children = []\n",
    "\n",
    "    for child in node.children:\n",
    "        new_child = simplify_graph(child)\n",
    "        new_node.add_children(new_child)\n",
    "        new_node.actual_time -= child.actual_time\n",
    "\n",
    "    if node.node_type in [\"Result\"]:\n",
    "        return node.children[0]\n",
    "\n",
    "    return new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3\n",
    "def to_text(node, skip=False):\n",
    "    global steps, cur_step, cur_table_name\n",
    "    increment = True\n",
    "    # skip the child if merge it with current node\n",
    "    if node.node_type in [\"Unique\", \"Aggregate\"] and len(node.children) == 1 \\\n",
    "            and (\"Scan\" in node.children[0].node_type or node.children[0].node_type == \"Sort\"):\n",
    "        children_skip = True\n",
    "    elif node.node_type == \"Bitmap Heap Scan\" and node.children[0].node_type == \"Bitmap Index Scan\":\n",
    "        children_skip = True\n",
    "    else:\n",
    "        children_skip = False\n",
    "\n",
    "    # recursive\n",
    "    for child in node.children:\n",
    "        if node.node_type == \"Aggregate\" and len(node.children) > 1 and child.node_type == \"Sort\":\n",
    "            to_text(child, True)\n",
    "        else:\n",
    "            to_text(child, children_skip)\n",
    "\n",
    "    if node.node_type in [\"Hash\"] or skip:\n",
    "        return\n",
    "\n",
    "    step = \"\"\n",
    "\n",
    "    # generate natural language for various QEP operators\n",
    "    if \"Join\" in node.node_type:\n",
    "        \n",
    "        # special preprocessing for joins\n",
    "        if node.join_type == \"Semi\":\n",
    "            # add the word \"Semi\" before \"Join\" into node.node_type\n",
    "            node_type_list = node.node_type.split()\n",
    "            node_type_list.insert(-1, node.join_type)\n",
    "            node.node_type = \" \".join(node_type_list)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if \"Hash\" in node.node_type:\n",
    "            step += \" and perform \" + node.node_type.lower() + \" on \"\n",
    "            for i, child in enumerate(node.children):\n",
    "                if child.node_type == \"Hash\":\n",
    "                    child.set_output_name(child.children[0].get_output_name())\n",
    "                    hashed_table = child.get_output_name()\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\"table \" + child.get_output_name())\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "            # combine hash with hash join\n",
    "            step = \"hash table \" + hashed_table + step + \" under condition \" + parse_cond(\"Hash Cond\", node.hash_cond, table_subquery_name_pair)\n",
    "        \n",
    "        elif \"Merge\" in node.node_type:\n",
    "            step += \"perform \" + node.node_type.lower() + \" on \"\n",
    "            any_sort = False  # whether sort is performed on any table\n",
    "            for i, child in enumerate(node.children):\n",
    "                if child.node_type == \"Sort\":\n",
    "                    child.set_output_name(child.children[0].get_output_name())\n",
    "                    any_sort = True\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\"table \" + child.get_output_name())\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "            # combine sort with merge join\n",
    "            if any_sort:\n",
    "                sort_step = \"sort \"\n",
    "                for child in node.children:\n",
    "                    if child.node_type == \"Sort\":\n",
    "                        if i < len(node.children) - 1:\n",
    "                            sort_step += (\"table \" + child.get_output_name())\n",
    "                        else:\n",
    "                            sort_step += (\" and table \" + child.get_output_name())\n",
    "                step = sort_step + \" and \" + step\n",
    "\n",
    "    elif node.node_type == \"Bitmap Heap Scan\":\n",
    "        # combine bitmap heap scan and bitmap index scan\n",
    "        if \"Bitmap Index Scan\" in node.children[0].node_type:\n",
    "            node.children[0].set_output_name(node.relation_name)\n",
    "            step = \" with index condition \" + parse_cond(\"Recheck Cond\", node.recheck_cond, table_subquery_name_pair)\n",
    "            \n",
    "        step = \"perform bitmap heap scan on table \" + node.children[0].get_output_name() + step\n",
    "\n",
    "    elif \"Scan\" in node.node_type:\n",
    "        if node.node_type == \"Seq Scan\":\n",
    "            step += \"perform sequential scan on table \"         \n",
    "        else:\n",
    "            step += \"perform \" + node.node_type.lower() + \" on table \" \n",
    "\n",
    "        step += node.get_output_name()\n",
    "\n",
    "        # if no table filter, remain original table name\n",
    "        if not node.table_filter:\n",
    "            increment = False\n",
    "\n",
    "    elif node.node_type == \"Unique\":\n",
    "        # combine unique and sort\n",
    "        if \"Sort\" in node.children[0].node_type:\n",
    "            node.children[0].set_output_name(node.children[0].children[0].get_output_name())\n",
    "            step = \"sort \" + node.children[0].get_output_name() \n",
    "            if node.children[0].sort_key:\n",
    "                step += \" with attribute \" + parse_cond(\"Sort Key\", node.children[0].sort_key, table_subquery_name_pair) +  \" and \"\n",
    "            else:\n",
    "                step += \" and \"\n",
    "\n",
    "        step += \"perform unique on table \" + node.children[0].get_output_name()\n",
    "\n",
    "    elif node.node_type == \"Aggregate\":\n",
    "        for child in node.children:\n",
    "            # combine aggregate and sort\n",
    "            if \"Sort\" in child.node_type:\n",
    "                child.set_output_name(child.children[0].get_output_name())\n",
    "                step = \"sort \" + child.get_output_name() + \" and \"\n",
    "            # combine aggregate with scan\n",
    "            if \"Scan\" in child.node_type:\n",
    "                if child.node_type == \"Seq Scan\":\n",
    "                    step = \"perform sequential scan on \" + child.get_output_name() + \" and \"\n",
    "                else:\n",
    "                    step = \"perform \" + child.node_type.lower() + \" on \" + child.get_output_name() + \" and \"\n",
    "\n",
    "        step += \"perform aggregate on table \" + node.children[0].get_output_name() \n",
    "        if len(node.children) == 2:\n",
    "            step += \" and table \" + node.children[1].get_output_name()\n",
    "\n",
    "    elif node.node_type == \"Sort\":\n",
    "        step += \"perform sort on table \" + node.children[0].get_output_name() + \" with attribute \" + parse_cond(\"Sort Key\", node.sort_key, table_subquery_name_pair) \n",
    "\n",
    "    elif node.node_type == \"Limit\":\n",
    "        step += \"limit the result from table \" + node.children[0].get_output_name() + \" to \" + str(node.plan_rows) + \" record(s)\"\n",
    "    \n",
    "    else:\n",
    "        step += \"perform \" + node.node_type.lower() + \" on\"\n",
    "        # binary operator\n",
    "        if len(node.children) > 1:\n",
    "            for i, child in enumerate(node.children):\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\" table \" + child.get_output_name() + \",\")\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "        # unary operator\n",
    "        else:\n",
    "            step += \" table \" + node.children[0].get_output_name()\n",
    "\n",
    "    # add conditions\n",
    "    if node.group_key:\n",
    "        step += \" with grouping on attribute \" + parse_cond(\"Group Key\", node.group_key, table_subquery_name_pair) \n",
    "    if node.table_filter:\n",
    "        step += \" and filtering on \" + parse_cond(\"Table Filter\", node.table_filter, table_subquery_name_pair)\n",
    "    if node.join_filter:\n",
    "        step += \" while filtering on \" + parse_cond(\"Join Filter\", node.join_filter, table_subquery_name_pair) \n",
    "\n",
    "    # set intermediate table name\n",
    "    if increment:\n",
    "        node.set_output_name(\"T\" + str(cur_table_name))\n",
    "        step += \" to get intermediate table \" + node.get_output_name()\n",
    "        cur_table_name += 1\n",
    "    if node.subplan_name:\n",
    "        table_subquery_name_pair[node.subplan_name] = node.get_output_name()\n",
    "\n",
    "    step = \"Step \" + str(cur_step) + \", \" + step + \".\"\n",
    "    node.set_step(cur_step)\n",
    "    cur_step += 1\n",
    "\n",
    "    steps.append(step) \n",
    "\n",
    "\n",
    "def random_word(length):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for _ in range(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--json_file JSON_FILE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/eric/Library/Jupyter/runtime/kernel-24c6a3aa-49dd-4185-974c-d17368b77797.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/.pyenv/versions/3.7.2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Phase 4\n",
    "def vocalize(steps):\n",
    "    logger = logging.getLogger(\"neuron.vocalizer.vocalize\")\n",
    "    txt = \"\"\n",
    "    for step in steps:\n",
    "        # pronounce the dot sign if it's not period\n",
    "        step = step.replace(\".\", \" dot \")\n",
    "        txt += step[:-5] + \". \"\n",
    "\n",
    "    random_name = random_word(10) + '.mp3'\n",
    "    random_file = os.path.join(os.path.dirname(os.path.realpath(__file__)), random_name)\n",
    "    \n",
    "    tts = gTTS(text=txt, lang='en')\n",
    "    logger.debug(\"Obtained TTS result from Google\")\n",
    "    with open(random_file, 'wb') as f:\n",
    "        tts.save(f.name)\n",
    "\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(f.name)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "\n",
    "def get_text(json_file):\n",
    "    global steps, cur_step, cur_table_name, table_subquery_name_pair\n",
    "    global current_plan_tree\n",
    "    steps = [\"The query is executed as follow.\"]\n",
    "    cur_step = 1\n",
    "    cur_table_name = 1\n",
    "    table_subquery_name_pair = {}\n",
    "\n",
    "    head_node = parse_json(json_file)\n",
    "    handler.current_plan_tree = simplified_graph = simplify_graph(head_node)\n",
    "\n",
    "    to_text(simplified_graph)\n",
    "    if \" to get intermediate table\" in steps[-1]:\n",
    "        steps[-1] = steps[-1][:steps[-1].index(\" to get intermediate table\")] + ' to get the final result.'\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--json_file',  type=str, default='./', help='the json generated file for vocalization')\n",
    "    args = parser.parse_args()\n",
    "    steps = get_text(args.json_file)\n",
    "    vocalize(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_1/query_1a.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Plan': {'Node Type': 'Sort', 'Parallel Aware': False, 'Startup Cost': 5783.27, 'Total Cost': 5783.57, 'Plan Rows': 120, 'Plan Width': 226, 'Actual Startup Time': 69.992, 'Actual Total Time': 69.994, 'Actual Rows': 25, 'Actual Loops': 1, 'Output': ['(avg(customer.acctbal))', 'nation.name'], 'Sort Key': ['(avg(customer.acctbal)) DESC'], 'Sort Method': 'quicksort', 'Sort Space Used': 26, 'Sort Space Type': 'Memory', 'Shared Hit Blocks': 1304, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Plans': [{'Node Type': 'Aggregate', 'Strategy': 'Sorted', 'Partial Mode': 'Finalize', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Startup Cost': 5748.43, 'Total Cost': 5779.13, 'Plan Rows': 120, 'Plan Width': 226, 'Actual Startup Time': 69.585, 'Actual Total Time': 69.978, 'Actual Rows': 25, 'Actual Loops': 1, 'Output': ['avg(customer.acctbal)', 'nation.name'], 'Group Key': ['nation.name'], 'Shared Hit Blocks': 1304, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Plans': [{'Node Type': 'Gather Merge', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Startup Cost': 5748.43, 'Total Cost': 5776.43, 'Plan Rows': 240, 'Plan Width': 250, 'Actual Startup Time': 69.575, 'Actual Total Time': 71.923, 'Actual Rows': 75, 'Actual Loops': 1, 'Output': ['nation.name', '(PARTIAL avg(customer.acctbal))'], 'Workers Planned': 2, 'Workers Launched': 2, 'Shared Hit Blocks': 3670, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Plans': [{'Node Type': 'Sort', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Startup Cost': 4748.4, 'Total Cost': 4748.7, 'Plan Rows': 120, 'Plan Width': 250, 'Actual Startup Time': 62.906, 'Actual Total Time': 62.908, 'Actual Rows': 25, 'Actual Loops': 3, 'Output': ['nation.name', '(PARTIAL avg(customer.acctbal))'], 'Sort Key': ['nation.name'], 'Sort Method': 'quicksort', 'Sort Space Used': 28, 'Sort Space Type': 'Memory', 'Workers': [{'Worker Number': 0, 'Actual Startup Time': 57.067, 'Actual Total Time': 57.07, 'Actual Rows': 25, 'Actual Loops': 1, 'Shared Hit Blocks': 1116, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}, {'Worker Number': 1, 'Actual Startup Time': 62.394, 'Actual Total Time': 62.396, 'Actual Rows': 25, 'Actual Loops': 1, 'Shared Hit Blocks': 1250, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}], 'Shared Hit Blocks': 3670, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Plans': [{'Node Type': 'Aggregate', 'Strategy': 'Hashed', 'Partial Mode': 'Partial', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Startup Cost': 4743.06, 'Total Cost': 4744.26, 'Plan Rows': 120, 'Plan Width': 250, 'Actual Startup Time': 62.822, 'Actual Total Time': 62.828, 'Actual Rows': 25, 'Actual Loops': 3, 'Output': ['nation.name', 'PARTIAL avg(customer.acctbal)'], 'Group Key': ['nation.name'], 'Shared Hit Blocks': 3654, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Workers': [{'Worker Number': 0, 'Actual Startup Time': 56.988, 'Actual Total Time': 56.995, 'Actual Rows': 25, 'Actual Loops': 1, 'Shared Hit Blocks': 1108, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}, {'Worker Number': 1, 'Actual Startup Time': 62.288, 'Actual Total Time': 62.294, 'Actual Rows': 25, 'Actual Loops': 1, 'Shared Hit Blocks': 1242, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}], 'Plans': [{'Node Type': 'Hash Join', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Join Type': 'Inner', 'Startup Cost': 12.7, 'Total Cost': 4430.56, 'Plan Rows': 62500, 'Plan Width': 226, 'Actual Startup Time': 0.16, 'Actual Total Time': 41.403, 'Actual Rows': 50000, 'Actual Loops': 3, 'Output': ['nation.name', 'customer.acctbal'], 'Inner Unique': True, 'Hash Cond': '(customer.nationkey = nation.nationkey)', 'Shared Hit Blocks': 3654, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Workers': [{'Worker Number': 0, 'Actual Startup Time': 0.295, 'Actual Total Time': 39.817, 'Actual Rows': 45221, 'Actual Loops': 1, 'Shared Hit Blocks': 1108, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}, {'Worker Number': 1, 'Actual Startup Time': 0.138, 'Actual Total Time': 44.689, 'Actual Rows': 50774, 'Actual Loops': 1, 'Shared Hit Blocks': 1242, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}], 'Plans': [{'Node Type': 'Seq Scan', 'Parent Relationship': 'Outer', 'Parallel Aware': True, 'Relation Name': 'customer', 'Schema': 'public', 'Alias': 'customer', 'Startup Cost': 0.0, 'Total Cost': 4248.0, 'Plan Rows': 62500, 'Plan Width': 12, 'Actual Startup Time': 0.016, 'Actual Total Time': 16.041, 'Actual Rows': 50000, 'Actual Loops': 3, 'Output': ['customer.custkey', 'customer.name', 'customer.address', 'customer.nationkey', 'customer.phone', 'customer.acctbal', 'customer.mktsegment', 'customer.comment'], 'Shared Hit Blocks': 3623, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Workers': [{'Worker Number': 0, 'Actual Startup Time': 0.019, 'Actual Total Time': 16.174, 'Actual Rows': 45221, 'Actual Loops': 1, 'Shared Hit Blocks': 1093, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}, {'Worker Number': 1, 'Actual Startup Time': 0.017, 'Actual Total Time': 17.642, 'Actual Rows': 50774, 'Actual Loops': 1, 'Shared Hit Blocks': 1227, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}]}, {'Node Type': 'Hash', 'Parent Relationship': 'Inner', 'Parallel Aware': False, 'Startup Cost': 11.2, 'Total Cost': 11.2, 'Plan Rows': 120, 'Plan Width': 222, 'Actual Startup Time': 0.06, 'Actual Total Time': 0.061, 'Actual Rows': 25, 'Actual Loops': 3, 'Output': ['nation.name', 'nation.nationkey'], 'Hash Buckets': 1024, 'Original Hash Buckets': 1024, 'Hash Batches': 1, 'Original Hash Batches': 1, 'Peak Memory Usage': 10, 'Shared Hit Blocks': 3, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Workers': [{'Worker Number': 0, 'Actual Startup Time': 0.087, 'Actual Total Time': 0.087, 'Actual Rows': 25, 'Actual Loops': 1, 'Shared Hit Blocks': 1, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}, {'Worker Number': 1, 'Actual Startup Time': 0.068, 'Actual Total Time': 0.068, 'Actual Rows': 25, 'Actual Loops': 1, 'Shared Hit Blocks': 1, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}], 'Plans': [{'Node Type': 'Seq Scan', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Relation Name': 'nation', 'Schema': 'public', 'Alias': 'nation', 'Startup Cost': 0.0, 'Total Cost': 11.2, 'Plan Rows': 120, 'Plan Width': 222, 'Actual Startup Time': 0.041, 'Actual Total Time': 0.045, 'Actual Rows': 25, 'Actual Loops': 3, 'Output': ['nation.name', 'nation.nationkey'], 'Shared Hit Blocks': 3, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0, 'Workers': [{'Worker Number': 0, 'Actual Startup Time': 0.062, 'Actual Total Time': 0.066, 'Actual Rows': 25, 'Actual Loops': 1, 'Shared Hit Blocks': 1, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}, {'Worker Number': 1, 'Actual Startup Time': 0.048, 'Actual Total Time': 0.051, 'Actual Rows': 25, 'Actual Loops': 1, 'Shared Hit Blocks': 1, 'Shared Read Blocks': 0, 'Shared Dirtied Blocks': 0, 'Shared Written Blocks': 0, 'Local Hit Blocks': 0, 'Local Read Blocks': 0, 'Local Dirtied Blocks': 0, 'Local Written Blocks': 0, 'Temp Read Blocks': 0, 'Temp Written Blocks': 0}]}]}]}]}]}]}]}]}, 'Planning Time': 0.177, 'Triggers': [], 'Execution Time': 72.423}]\n"
     ]
    }
   ],
   "source": [
    "with open(json_file) as jf:\n",
    "    data = json.load(jf)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_node = parse_json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sort'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_node.node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate\n"
     ]
    }
   ],
   "source": [
    "for node in head_node.children:\n",
    "    print(node.node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_node_info(head_node):\n",
    "    print(head_node.node_type)\n",
    "    print(len(head_node.children))\n",
    "    print(head_node.children)\n",
    "    print(head_node.relation_name)\n",
    "    print(head_node.schema)\n",
    "    print(head_node.alias)\n",
    "    print(head_node.group_key)\n",
    "    print(head_node.sort_key)\n",
    "    print(head_node.join_type)\n",
    "    print(head_node.index_name)\n",
    "    print(head_node.hash_cond)\n",
    "    print(head_node.table_filter)\n",
    "    print(head_node.index_cond)\n",
    "    print(head_node.merge_cond)\n",
    "    print(head_node.recheck_cond)\n",
    "    print(head_node.join_filter)\n",
    "    print(head_node.subplan_name)\n",
    "    print(head_node.actual_rows)\n",
    "    print(head_node.actual_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort\n",
      "1\n",
      "[<__main__.Node object at 0x102bb8588>]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "['(avg(customer.acctbal)) DESC']\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "25\n",
      "69.994\n"
     ]
    }
   ],
   "source": [
    "print_node_info(head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_head_node = simplify_graph(head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort\n",
      "1\n",
      "[<__main__.Node object at 0x102bb88d0>]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "['(avg(customer.acctbal)) DESC']\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "25\n",
      "0.016000000000005343\n"
     ]
    }
   ],
   "source": [
    "print_node_info(new_head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_tree(node, file=None, _prefix=\"\", _last=True):\n",
    "    print(_prefix, \"`- \" if _last else \"|- \", node.node_type, sep=\"\", file=file)\n",
    "    _prefix += \"   \" if _last else \"|  \"\n",
    "    child_count = len(node.children)\n",
    "    for i, child in enumerate(node.children):\n",
    "        _last = i == (child_count - 1)\n",
    "        pprint_tree(child, file, _prefix, _last) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`- Sort\n",
      "   `- Aggregate\n",
      "      `- Gather Merge\n",
      "         `- Sort\n",
      "            `- Aggregate\n",
      "               `- Hash Join\n",
      "                  |- Seq Scan\n",
      "                  `- Hash\n",
      "                     `- Seq Scan\n"
     ]
    }
   ],
   "source": [
    "pprint_tree(head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`- Sort\n",
      "   `- Aggregate\n",
      "      `- Gather Merge\n",
      "         `- Sort\n",
      "            `- Aggregate\n",
      "               `- Hash Join\n",
      "                  |- Seq Scan\n",
      "                  `- Hash\n",
      "                     `- Seq Scan\n"
     ]
    }
   ],
   "source": [
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_1/query_1b.json\"\n",
    "head_node = parse_json(json_file)\n",
    "pprint_tree(head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`- Sort\n",
      "   `- Aggregate\n",
      "      `- Gather Merge\n",
      "         `- Aggregate\n",
      "            `- Sort\n",
      "               `- Hash Join\n",
      "                  |- Hash Join\n",
      "                  |  |- Seq Scan\n",
      "                  |  `- Hash\n",
      "                  |     `- Seq Scan\n",
      "                  `- Hash\n",
      "                     `- Seq Scan\n",
      "##############################\n",
      "`- Sort\n",
      "   `- Aggregate\n",
      "      `- Gather Merge\n",
      "         `- Aggregate\n",
      "            `- Sort\n",
      "               `- Hash Join\n",
      "                  |- Hash Join\n",
      "                  |  |- Seq Scan\n",
      "                  |  `- Hash\n",
      "                  |     `- Seq Scan\n",
      "                  `- Hash\n",
      "                     `- Seq Scan\n"
     ]
    }
   ],
   "source": [
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_2/query_2a.json\"\n",
    "head_node = parse_json(json_file)\n",
    "pprint_tree(head_node)\n",
    "\n",
    "print(\"##############################\")\n",
    "\n",
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_2/query_2b.json\"\n",
    "head_node = parse_json(json_file)\n",
    "pprint_tree(head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`- Sort\n",
      "   `- Aggregate\n",
      "      `- Gather Merge\n",
      "         `- Sort\n",
      "            `- Aggregate\n",
      "               `- Hash Join\n",
      "                  |- Hash Join\n",
      "                  |  |- Seq Scan\n",
      "                  |  `- Hash\n",
      "                  |     `- Seq Scan\n",
      "                  `- Hash\n",
      "                     `- Seq Scan\n",
      "##############################\n",
      "`- Sort\n",
      "   `- Aggregate\n",
      "      `- Gather Merge\n",
      "         `- Sort\n",
      "            `- Aggregate\n",
      "               `- Hash Join\n",
      "                  |- Seq Scan\n",
      "                  `- Hash\n",
      "                     `- Seq Scan\n"
     ]
    }
   ],
   "source": [
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_3/query_3a.json\"\n",
    "head_node = parse_json(json_file)\n",
    "pprint_tree(head_node)\n",
    "\n",
    "print(\"##############################\")\n",
    "\n",
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_3/query_3b.json\"\n",
    "head_node = parse_json(json_file)\n",
    "pprint_tree(head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`- Sort\n",
      "   `- Aggregate\n",
      "      `- Gather Merge\n",
      "         `- Sort\n",
      "            `- Aggregate\n",
      "               `- Hash Join\n",
      "                  |- Seq Scan\n",
      "                  `- Hash\n",
      "                     `- Seq Scan\n",
      "##############################\n",
      "`- Sort\n",
      "   `- Aggregate\n",
      "      `- Gather Merge\n",
      "         `- Sort\n",
      "            `- Aggregate\n",
      "               `- Hash Join\n",
      "                  |- Seq Scan\n",
      "                  `- Hash\n",
      "                     `- Seq Scan\n"
     ]
    }
   ],
   "source": [
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_4/query_4a.json\"\n",
    "head_node = parse_json(json_file)\n",
    "pprint_tree(head_node)\n",
    "\n",
    "print(\"##############################\")\n",
    "\n",
    "json_file = \"/Users/eric/Desktop/CZ4031-PostgresqlQuery-Description/queries/query_4/query_4b.json\"\n",
    "head_node = parse_json(json_file)\n",
    "pprint_tree(head_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
