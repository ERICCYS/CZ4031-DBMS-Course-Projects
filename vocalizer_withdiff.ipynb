{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import json\n",
    "import argparse\n",
    "import copy\n",
    "import random, string\n",
    "import os\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, node_type, relation_name, schema, alias, group_key, sort_key, join_type, index_name, \n",
    "            hash_cond, table_filter, index_cond, merge_cond, recheck_cond, join_filter, subplan_name, actual_rows,\n",
    "            actual_time,description):\n",
    "        self.node_type = node_type\n",
    "        self.children = []\n",
    "        self.relation_name = relation_name\n",
    "        self.schema = schema\n",
    "        self.alias = alias\n",
    "        self.group_key = group_key\n",
    "        self.sort_key = sort_key\n",
    "        self.join_type = join_type\n",
    "        self.index_name = index_name\n",
    "        self.hash_cond = hash_cond\n",
    "        self.table_filter = table_filter\n",
    "        self.index_cond = index_cond\n",
    "        self.merge_cond = merge_cond\n",
    "        self.recheck_cond = recheck_cond\n",
    "        self.join_filter = join_filter\n",
    "        self.subplan_name = subplan_name\n",
    "        self.actual_rows = actual_rows\n",
    "        self.actual_time = actual_time\n",
    "        self.description = description\n",
    "\n",
    "    def add_children(self, child):\n",
    "        self.children.append(child)\n",
    "    \n",
    "    def set_output_name(self, output_name):\n",
    "        if \"T\" == output_name[0] and output_name[1:].isdigit():\n",
    "            self.output_name = int(output_name[1:])\n",
    "        else:\n",
    "            self.output_name = output_name\n",
    "\n",
    "    def get_output_name(self):\n",
    "        if str(self.output_name).isdigit():\n",
    "            return \"T\" + str(self.output_name)\n",
    "        else:\n",
    "            return self.output_name\n",
    "\n",
    "    def set_step(self, step):\n",
    "        self.step = step\n",
    "    \n",
    "    def update_desc(self,desc):\n",
    "        self.description = desc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1\n",
    "def parse_json(json_file):\n",
    "    q = queue.Queue()\n",
    "    q_node = queue.Queue()\n",
    "    json_obj = json.load(open(json_file, 'r'))\n",
    "    plan = json_obj[0]['Plan']\n",
    "    q.put(plan)\n",
    "    q_node.put(None)\n",
    "\n",
    "    while not q.empty():\n",
    "        current_plan = q.get()\n",
    "        parent_node = q_node.get()\n",
    "\n",
    "        relation_name = schema = alias = group_key = sort_key = join_type = index_name = hash_cond = table_filter \\\n",
    "            = index_cond = merge_cond = recheck_cond = join_filter = subplan_name = actual_rows = actual_time = description= None\n",
    "        if 'Relation Name' in current_plan:\n",
    "            relation_name = current_plan['Relation Name']\n",
    "        if 'Schema' in current_plan:\n",
    "            schema = current_plan['Schema']\n",
    "        if 'Alias' in current_plan:\n",
    "            alias = current_plan['Alias']\n",
    "        if 'Group Key' in current_plan:\n",
    "            group_key = current_plan['Group Key']\n",
    "        if 'Sort Key' in current_plan:\n",
    "            sort_key = current_plan['Sort Key']\n",
    "        if 'Join Type' in current_plan:\n",
    "            join_type = current_plan['Join Type']\n",
    "        if 'Index Name' in current_plan:\n",
    "            index_name = current_plan['Index Name']\n",
    "        if 'Hash Cond' in current_plan:\n",
    "            hash_cond = current_plan['Hash Cond']\n",
    "        if 'Filter' in current_plan:\n",
    "            table_filter = current_plan['Filter']\n",
    "        if 'Index Cond' in current_plan:\n",
    "            index_cond = current_plan['Index Cond']\n",
    "        if 'Merge Cond' in current_plan:\n",
    "            merge_cond = current_plan['Merge Cond']\n",
    "        if 'Recheck Cond' in current_plan:\n",
    "            recheck_cond = current_plan['Recheck Cond']\n",
    "        if 'Join Filter' in current_plan:\n",
    "            join_filter = current_plan['Join Filter']\n",
    "        if 'Actual Rows' in current_plan:\n",
    "            actual_rows = current_plan['Actual Rows']\n",
    "        if 'Actual Total Time' in current_plan:\n",
    "            actual_time = current_plan['Actual Total Time']\n",
    "        if 'Subplan Name' in current_plan:\n",
    "            if \"returns\" in current_plan['Subplan Name']:\n",
    "                name = current_plan['Subplan Name']\n",
    "                subplan_name = name[name.index(\"$\"):-1]\n",
    "            else:\n",
    "                subplan_name = current_plan['Subplan Name']\n",
    "\n",
    "        current_node = Node(current_plan['Node Type'], relation_name, schema, alias, group_key, sort_key, join_type,\n",
    "                            index_name, hash_cond, table_filter, index_cond, merge_cond, recheck_cond, join_filter,\n",
    "                            subplan_name, actual_rows, actual_time,description)\n",
    "\n",
    "        if \"Limit\" == current_node.node_type:\n",
    "            current_node.plan_rows = current_plan['Plan Rows']\n",
    "           \n",
    "        if \"Scan\" in current_node.node_type:\n",
    "            if \"Index\" in current_node.node_type:\n",
    "                if relation_name:\n",
    "                    current_node.set_output_name(relation_name + \" with index \" + index_name)\n",
    "            elif \"Subquery\" in current_node.node_type:\n",
    "                current_node.set_output_name(alias)\n",
    "            else:\n",
    "                current_node.set_output_name(relation_name)\n",
    "\n",
    "        if parent_node is not None:\n",
    "            parent_node.add_children(current_node)\n",
    "        else:\n",
    "            head_node = current_node\n",
    "\n",
    "        if 'Plans' in current_plan:\n",
    "            for item in current_plan['Plans']:\n",
    "                # push child plans into queue\n",
    "                q.put(item)\n",
    "                # push parent for each child into queue\n",
    "                q_node.put(current_node)\n",
    "\n",
    "    return head_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2\n",
    "def simplify_graph(node):\n",
    "    new_node = copy.deepcopy(node)\n",
    "    new_node.children = []\n",
    "\n",
    "    for child in node.children:\n",
    "        new_child = simplify_graph(child)\n",
    "        new_node.add_children(new_child)\n",
    "        new_node.actual_time -= child.actual_time\n",
    "\n",
    "    if node.node_type in [\"Result\"]:\n",
    "        return node.children[0]\n",
    "\n",
    "    return new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3\n",
    "def parse_cond(op_name, conditions, table_subquery_name_pair):\n",
    "#     print(\"conditions\")\n",
    "#     print(\"type: {}\".format(type(conditions)))\n",
    "#     print(conditions)\n",
    "    if isinstance(conditions,str):\n",
    "        return conditions[1:-1]\n",
    "    cond = \"\"\n",
    "    for i in range (len(conditions)):\n",
    "        cond = cond + conditions[i]\n",
    "        if (not (i == len(conditions)-1)):\n",
    "            cond = cond + \"and\"\n",
    "    return cond\n",
    "\n",
    "def to_text(node, skip=False):\n",
    "#     print(node.node_type)\n",
    "    global steps, cur_step, cur_table_name\n",
    "    increment = True\n",
    "    # skip the child if merge it with current node\n",
    "    if node.node_type in [\"Unique\", \"Aggregate\"] and len(node.children) == 1 \\\n",
    "            and (\"Scan\" in node.children[0].node_type or node.children[0].node_type == \"Sort\"):\n",
    "        children_skip = True\n",
    "    elif node.node_type == \"Bitmap Heap Scan\" and node.children[0].node_type == \"Bitmap Index Scan\":\n",
    "        children_skip = True\n",
    "    else:\n",
    "        children_skip = False\n",
    "    \n",
    "#     print(children_skip)\n",
    "    # recursive\n",
    "    for child in node.children:\n",
    "        if node.node_type == \"Aggregate\" and len(node.children) > 1 and child.node_type == \"Sort\":\n",
    "            to_text(child, True)\n",
    "        else:\n",
    "            to_text(child, children_skip)\n",
    "\n",
    "    if node.node_type in [\"Hash\"] or skip:\n",
    "        return\n",
    "    \n",
    "    step = \"\"\n",
    "#     print(\"step: {}\".format(step))\n",
    "    \n",
    "\n",
    "    # generate natural language for various QEP operators\n",
    "    if \"Join\" in node.node_type:\n",
    "#         print(\"Join as node type\")\n",
    "        # special preprocessing for joins\n",
    "        if node.join_type == \"Semi\":\n",
    "            # add the word \"Semi\" before \"Join\" into node.node_type\n",
    "            node_type_list = node.node_type.split()\n",
    "            node_type_list.insert(-1, node.join_type)\n",
    "            node.node_type = \" \".join(node_type_list)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if \"Hash\" in node.node_type:\n",
    "            step += \" and then perform \" + node.node_type.lower() + \" on \"\n",
    "            for i, child in enumerate(node.children):\n",
    "                if child.node_type == \"Hash\":\n",
    "                    child.set_output_name(child.children[0].get_output_name())\n",
    "                    hashed_table = child.get_output_name()\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\"table \" + child.get_output_name())\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "            # combine hash with hash join\n",
    "            step = \"hash on table \" + hashed_table + step\n",
    "#             print(\"###########\")\n",
    "#             print(node.group_key)\n",
    "#             print(\"###########\")\n",
    "#             step = \"hash table \" + hashed_table + step + \" under condition \" + \"##parse_cond(\\\"Hash Cond\\\", node.hash_cond, table_subquery_name_pair)##\"\n",
    "            \n",
    "        \n",
    "        elif \"Merge\" in node.node_type:\n",
    "            step += \"perform \" + node.node_type.lower() + \" on \"\n",
    "            any_sort = False  # whether sort is performed on any table\n",
    "            for i, child in enumerate(node.children):\n",
    "                if child.node_type == \"Sort\":\n",
    "                    child.set_output_name(child.children[0].get_output_name())\n",
    "                    any_sort = True\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\"table \" + child.get_output_name())\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "            # combine sort with merge join\n",
    "            if any_sort:\n",
    "                sort_step = \"sort \"\n",
    "                for child in node.children:\n",
    "                    if child.node_type == \"Sort\":\n",
    "                        if i < len(node.children) - 1:\n",
    "                            sort_step += (\"table \" + child.get_output_name())\n",
    "                        else:\n",
    "                            sort_step += (\" and table \" + child.get_output_name())\n",
    "                step = sort_step + \" and \" + step\n",
    "\n",
    "    elif node.node_type == \"Bitmap Heap Scan\":\n",
    "#         print(\"Bitmap Heap Scan as node type\")\n",
    "        # combine bitmap heap scan and bitmap index scan\n",
    "        if \"Bitmap Index Scan\" in node.children[0].node_type:\n",
    "            node.children[0].set_output_name(node.relation_name)\n",
    "            step = \" with index condition \" + parse_cond(\"Recheck Cond\", node.recheck_cond, table_subquery_name_pair)\n",
    "#             print(\"###########\")\n",
    "#             print(node.group_key)\n",
    "#             print(\"###########\")\n",
    "#             step = \" with index condition \" + \"##parse_cond(\\\"Recheck Cond\\\", node.recheck_cond, table_subquery_name_pair)##\"\n",
    "            \n",
    "            \n",
    "        step = \"perform bitmap heap scan on table \" + node.children[0].get_output_name() + step\n",
    "\n",
    "    elif \"Scan\" in node.node_type:\n",
    "#         print(\"Scan as node type\")\n",
    "        \n",
    "        if node.node_type == \"Seq Scan\":\n",
    "            step += \"perform sequential scan on table \"         \n",
    "        else:\n",
    "            step += \"perform \" + node.node_type.lower() + \" on table \" \n",
    "\n",
    "        step += node.get_output_name()\n",
    "\n",
    "        # if no table filter, remain original table name\n",
    "        if not node.table_filter:\n",
    "            increment = False\n",
    "\n",
    "    elif node.node_type == \"Unique\":\n",
    "#         print(\"Unique as node type\")\n",
    "        # combine unique and sort\n",
    "        if \"Sort\" in node.children[0].node_type:\n",
    "            node.children[0].set_output_name(node.children[0].children[0].get_output_name())\n",
    "            step = \"sort \" + node.children[0].get_output_name() \n",
    "            if node.children[0].sort_key:\n",
    "                step += \" with attribute \" + parse_cond(\"Sort Key\", node.children[0].sort_key, table_subquery_name_pair) +  \" and \"\n",
    "#                 print(\"###########\")\n",
    "#                 print(node.group_key)\n",
    "#                 print(\"###########\")\n",
    "#                 step += \" with attribute \" + \"##parse_cond(\\\"Sort Key\\\", node.children[0].sort_key, table_subquery_name_pair)##\" +  \" and \"\n",
    "                \n",
    "            else:\n",
    "                step += \" and \"\n",
    "\n",
    "        step += \"perform unique on table \" + node.children[0].get_output_name()\n",
    "\n",
    "    elif node.node_type == \"Aggregate\":\n",
    "#         print(\"Aggregate as node type\")\n",
    "#         print(\"###########\")\n",
    "#         print(node.group_key)\n",
    "#         print(\"###########\")\n",
    "        for child in node.children:\n",
    "            # combine aggregate and sort\n",
    "            if \"Sort\" in child.node_type:\n",
    "                child.set_output_name(child.children[0].get_output_name())\n",
    "                step = \"sort \" + child.get_output_name() + \" and \"\n",
    "            # combine aggregate with scan\n",
    "            if \"Scan\" in child.node_type:\n",
    "                if child.node_type == \"Seq Scan\":\n",
    "                    step = \"perform sequential scan on \" + child.get_output_name() + \" and \"\n",
    "                else:\n",
    "                    step = \"perform \" + child.node_type.lower() + \" on \" + child.get_output_name() + \" and \"\n",
    "\n",
    "        step += \"perform aggregate on table \" + node.children[0].get_output_name() \n",
    "        if len(node.children) == 2:\n",
    "            step += \" and table \" + node.children[1].get_output_name()\n",
    "\n",
    "    elif node.node_type == \"Sort\":\n",
    "#         print(\"Sort as node type\")\n",
    "#         print(\"###########\")\n",
    "#         print(node.group_key)\n",
    "#         print(\"###########\")\n",
    "        step += \"perform sort on table \" + node.children[0].get_output_name() + \" with attribute \" + parse_cond(\"Sort Key\", node.sort_key, table_subquery_name_pair) \n",
    "#         step += \"perform sort on table \" + node.children[0].get_output_name() + \" with attribute \" + \"##parse_cond(\\\"Sort Key\\\", node.sort_key, table_subquery_name_pair)##\" \n",
    "        \n",
    "\n",
    "    elif node.node_type == \"Limit\":\n",
    "#         print(\"Limit as node type\")\n",
    "        \n",
    "        step += \"limit the result from table \" + node.children[0].get_output_name() + \" to \" + str(node.plan_rows) + \" record(s)\"\n",
    "    \n",
    "    else:\n",
    "        step += \"perform \" + node.node_type.lower() + \" on\"\n",
    "        # binary operator\n",
    "        if len(node.children) > 1:\n",
    "            for i, child in enumerate(node.children):\n",
    "                if i < len(node.children) - 1:\n",
    "                    step += (\" table \" + child.get_output_name())\n",
    "                else:\n",
    "                    step += (\" and table \" + child.get_output_name())\n",
    "        # unary operator\n",
    "        else:\n",
    "            step += \" table \" + node.children[0].get_output_name()\n",
    "\n",
    "    # add conditions\n",
    "    if node.group_key:\n",
    "        step += \" with grouping on attribute \" + parse_cond(\"Group Key\", node.group_key, table_subquery_name_pair)\n",
    "#         print(\"###########\")\n",
    "#         print(node.group_key)\n",
    "#         print(\"###########\")\n",
    "#         step += \" with grouping on attribute \" + \"##parse_cond(\\\"Group Key\\\", node.group_key, table_subquery_name_pair)##\"\n",
    "        \n",
    "    if node.table_filter:\n",
    "        step += \" and filtering on \" + parse_cond(\"Table Filter\", node.table_filter, table_subquery_name_pair)\n",
    "#         print(\"###########\")\n",
    "#         print(node.group_key)\n",
    "#         print(\"###########\")\n",
    "#         step += \" and filtering on \" + \"##parse_cond(\\\"Table Filter\\\", node.table_filter, table_subquery_name_pair)##\"\n",
    "    if node.join_filter:\n",
    "        step += \" while filtering on \" + parse_cond(\"Join Filter\", node.join_filter, table_subquery_name_pair) \n",
    "#         print(\"###########\")\n",
    "#         print(node.group_key)\n",
    "#         print(\"###########\")\n",
    "#         step += \" while filtering on \" + \"##parse_cond(\\\"Join Filter\\\", node.join_filter, table_subquery_name_pair)##\" \n",
    "        \n",
    "\n",
    "    # set intermediate table name\n",
    "    if increment:\n",
    "        node.set_output_name(\"T\" + str(cur_table_name))\n",
    "        step += \" to get intermediate table \" + node.get_output_name()\n",
    "        cur_table_name += 1\n",
    "    if node.subplan_name:\n",
    "        table_subquery_name_pair[node.subplan_name] = node.get_output_name()\n",
    "    \n",
    "    node.update_desc(step)\n",
    "    step = \"Step \" + str(cur_step) + \", \" + step + \".\"\n",
    "    node.set_step(cur_step)\n",
    "    cur_step += 1\n",
    "\n",
    "    steps.append(step) \n",
    "\n",
    "\n",
    "def random_word(length):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for _ in range(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4\n",
    "def vocalize(steps):\n",
    "    logger = logging.getLogger(\"neuron.vocalizer.vocalize\")\n",
    "    txt = \"\"\n",
    "    for step in steps:\n",
    "        # pronounce the dot sign if it's not period\n",
    "        step = step.replace(\".\", \" dot \")\n",
    "        txt += step[:-5] + \". \"\n",
    "\n",
    "    random_name = random_word(10) + '.mp3'\n",
    "    random_file = os.path.join(os.path.dirname(os.path.realpath(__file__)), random_name)\n",
    "    \n",
    "    tts = gTTS(text=txt, lang='en')\n",
    "    logger.debug(\"Obtained TTS result from Google\")\n",
    "    with open(random_file, 'wb') as f:\n",
    "        tts.save(f.name)\n",
    "\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(f.name)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "\n",
    "def get_text(json_file):\n",
    "    global steps, cur_step, cur_table_name, table_subquery_name_pair\n",
    "    global current_plan_tree\n",
    "    steps = [\"The query is executed as follow.\"]\n",
    "    cur_step = 1\n",
    "    cur_table_name = 1\n",
    "    table_subquery_name_pair = {}\n",
    "\n",
    "    head_node = parse_json(json_file)\n",
    "#     handler.current_plan_tree = \n",
    "    simplified_graph = simplify_graph(head_node)\n",
    "\n",
    "    to_text(simplified_graph)\n",
    "    if \" to get intermediate table\" in steps[-1]:\n",
    "        steps[-1] = steps[-1][:steps[-1].index(\" to get intermediate table\")] + ' to get the final result.'\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_tree(node, file=None, _prefix=\"\", _last=True):\n",
    "    print(_prefix, \"`- \" if _last else \"|- \", node.node_type, sep=\"\", file=file)\n",
    "    _prefix += \"   \" if _last else \"|  \"\n",
    "    child_count = len(node.children)\n",
    "    for i, child in enumerate(node.children):\n",
    "        _last = i == (child_count - 1)\n",
    "        pprint_tree(child, file, _prefix, _last) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query is executed as follow.\n",
      "Step 1, perform sequential scan on table lineitem and filtering on lineitem.suppkey = 10 to get intermediate table T1.\n",
      "Step 2, perform sequential scan on table partsupp and filtering on partsupp.suppkey = 10 to get intermediate table T2.\n",
      "Step 3, hash on table T2 and then perform hash join on table T1 and table T2 to get intermediate table T3.\n",
      "Step 4, perform gather on table T3 to get the final result.\n",
      "`- Gather\n",
      "   `- Hash Join\n",
      "      |- Seq Scan\n",
      "      `- Hash\n",
      "         `- Seq Scan\n",
      "\n",
      "##############################\n",
      "\n",
      "The query is executed as follow.\n",
      "Step 1, perform sequential scan on table partsupp and filtering on (partsupp.partkey < 20) AND (partsupp.suppkey = 10) to get intermediate table T1.\n",
      "Step 2, perform gather on table T1 to get intermediate table T2.\n",
      "Step 3, perform sequential scan on table lineitem and filtering on lineitem.suppkey = 10 to get intermediate table T3.\n",
      "Step 4, perform gather on table T3 to get intermediate table T4.\n",
      "Step 5, perform nested loop on table T2 and table T4 while filtering on partsupp.partkey = lineitem.partkey to get the final result.\n",
      "`- Nested Loop\n",
      "   |- Gather\n",
      "   |  `- Seq Scan\n",
      "   `- Gather\n",
      "      `- Seq Scan\n"
     ]
    }
   ],
   "source": [
    "json_file_1a = \"query_7a.json\"\n",
    "head_node_1a = parse_json(json_file_1a)\n",
    "\n",
    "\n",
    "for step in get_text(json_file_1a):\n",
    "    print(step)\n",
    "pprint_tree(head_node_1a)\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"##############################\")\n",
    "\n",
    "print()\n",
    "json_file_1b = \"query_7b.json\"\n",
    "head_node_1b = parse_json(json_file_1b)\n",
    "\n",
    "\n",
    "\n",
    "for step in get_text(json_file_1b):\n",
    "    print(step)\n",
    "pprint_tree(head_node_1b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference 1 : gather on table T9 to get intermediate table T10 has been changed to nested loop on table T12 and table T14 while filtering on partsupp.partkey = lineitem.partkey to get intermediate table T15\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_file_1a = \"query_7a.json\"\n",
    "head_node_a = parse_json(json_file_1a)\n",
    "to_text(head_node_a)\n",
    "\n",
    "json_file_1b = \"query_7b.json\"\n",
    "head_node_b = parse_json(json_file_1b)\n",
    "to_text(head_node_b)\n",
    "\n",
    "def modify_text(str):\n",
    "    str = str.replace('perform ','')\n",
    "    return str\n",
    "\n",
    "num = 1\n",
    "\n",
    "def check_children(nodeA,nodeB):\n",
    "    global num\n",
    "    #num =1\n",
    "    childrenA = nodeA.children\n",
    "    childrenB = nodeB.children\n",
    "    children_no_A = len(childrenA)\n",
    "    children_no_B = len(childrenB)\n",
    "    \n",
    "    if nodeA.node_type == nodeB.node_type and children_no_A == children_no_B:\n",
    "        if children_no_A!= 0:\n",
    "            for i in range(len(childrenA)):\n",
    "                if childrenA[i].node_type != childrenB[i].node_type:\n",
    "                    text = 'Difference '+ str(num) + ' : ' + nodeA.description + ' has been changed to '+ nodeB.description\n",
    "                    text = modify_text(text)\n",
    "                    print(text)\n",
    "                    print('\\n')\n",
    "                    num +=1\n",
    "                    check_children(childrenA[i],childrenB[i])\n",
    "                    #print('if')\n",
    "                else:\n",
    "                    check_children(childrenA[i],childrenB[i])\n",
    "                    #print('else')\n",
    "            \n",
    "    else:\n",
    "        if nodeA.node_type == 'Hash':\n",
    "            text = 'Difference '+ str(num) + ' : ' + nodeA.children[0].description + ' has been changed to '+ nodeB.description\n",
    "            text = modify_text(text)\n",
    "            print(text)\n",
    "            print('\\n')\n",
    "            num +=1\n",
    "        elif nodeB.node_type == 'Hash':\n",
    "            text = 'Difference '+ str(num) + ' : ' + nodeA.description + ' has been changed to '+ nodeB.children[0].description\n",
    "            text = modify_text(text)\n",
    "            print(text)\n",
    "            print('\\n')\n",
    "            num +=1\n",
    "        else:\n",
    "            text = 'Difference '+ str(num) + ' : ' + nodeA.description + ' has been changed to '+ nodeB.description\n",
    "            text = modify_text(text)\n",
    "            print(text)\n",
    "            print('\\n')\n",
    "            num +=1\n",
    "        \n",
    "        if children_no_A == children_no_B:\n",
    "            if children_no_A == 1:\n",
    "                check_children(childrenA[0],childrenB[0])\n",
    "            if children_no_A == 2:\n",
    "                check_children(childrenA[0],childrenB[0])\n",
    "                check_children(childrenA[1],childrenB[1])\n",
    "\n",
    "check_children(head_node_a,head_node_b)\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
